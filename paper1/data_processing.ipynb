{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing \n",
    "\n",
    "In this notebook we take observations from the fully cryogenic WISE observing run (provided by Nathan Myhrvold) and filter and clean them to create a high quality sample of observations which can be used for thermal modeling.\n",
    "\n",
    "This filtering includes:\n",
    "- a minimum SNR of 4 in all four bandpasses\n",
    "- quality flags should contain A, B or C\n",
    "- quality flags should not contain X or U\n",
    "- artifact flags should be \"0000\" \n",
    "- a minimum of 3 observations in each bandpass\n",
    "\n",
    "The final subsample of observations is then crossmatched with the 2016 NEOWISE PDS release. Both the observations and the NEOWISE results are then read into a sqlite database located here: \n",
    "\n",
    "Finally, we repeat a similar exercise but grab all observations from the full cryogenic run that have observations in W3. This sample is also read into a database and is used to make comparisons of our W3 diameter estimators (described in Section 4 of the paper) with the published NEOWISE best-fit diameters and albedos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import io\n",
    "import os\n",
    "import zipfile\n",
    "import urllib\n",
    "import sqlite3 as sql\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find PDS4 tools. Attempting download...\n",
      "File succesfully downloaded.\n",
      "Decompressing...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# add PDS4 reader code (http://sbndev.astro.umd.edu/wiki/Python_PDS4_Tools)\n",
    "pds4_package = \"../data/PDS4_tools-1.1.zip\"\n",
    "if os.path.isdir(\"../data/PDS4_tools-1.1\") is not True:\n",
    "    print(\"Could not find PDS4 tools. Attempting download...\")\n",
    "    url = 'http://pdssbn.astro.umd.edu/ftp/tools/readpds_python/1.1/PDS4_tools-1.1.zip'  \n",
    "    urllib.request.urlretrieve(url, pds4_package)  \n",
    "    print(\"File succesfully downloaded.\")\n",
    "    \n",
    "    print(\"Decompressing...\")\n",
    "    zip_ref = zipfile.ZipFile(pds4_package, 'r')\n",
    "    zip_ref.extractall(\"../data/PDS4_tools-1.1\")\n",
    "    zip_ref.close()\n",
    "    \n",
    "else:\n",
    "    print(\"PDS4 tools has already been downloaded...\")\n",
    "print(\"Done.\")\n",
    "    \n",
    "sys.path.append(\"../data/PDS4_tools-1.1/pds4_tools-1.1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pds4_tools\n",
    "\n",
    "from atm import Constants as c\n",
    "from atm.obs import WISE\n",
    "from atm import clipObservations\n",
    "from atm import crossmatchNEOWISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 2542956 observations of 150928 unique asteroids.\n",
      "Cut data has 87293 observations of 9672 unique asteroids.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moeyensj/software/anaconda3/envs/atm_py36/lib/python3.6/site-packages/ipykernel_launcher.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/moeyensj/software/anaconda3/envs/atm_py36/lib/python3.6/site-packages/ipykernel_launcher.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations that were cut: 12344 (14.14%)\n",
      "Number of observations that survived cut: 74949 (85.86%)\n",
      "Number of unique objects that were cut: 2309 (23.87%)\n",
      "Number of unique objects that survived cut: 7363 (76.13%)\n",
      "The observations DataFrame has been updated: see observations['keep'] for clipping flag.\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_centaurs.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_irreg_sat.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_hildas.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_neos.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_mainbelt.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_ambos.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_jupiter_trojans.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Crossmatched 9236 unique designations from observations with NEOWISE table.\n"
     ]
    }
   ],
   "source": [
    "DO_PROCESSING = True\n",
    "DATABASE = \"../data/sample.db\"\n",
    "\n",
    "if DO_PROCESSING:\n",
    "\n",
    "    ### Read in full data file\n",
    "    data = pd.read_csv(\"../data/fullcryoobservations.csv\", low_memory=False)\n",
    "\n",
    "    ### Sort values by name and mjd\n",
    "    data.sort_values(by=[\"nameasstring\", \"mjd\"], inplace=True)\n",
    "\n",
    "    ### Make same cuts as Nathan to produce a gold standard\n",
    "    #-          SNR >= 4.0\n",
    "    #-          Artifact flag = 0\n",
    "    #-          Quality flag = A, B, C\n",
    "    #-          Have at least 3 points in each of the four bands\n",
    "    # See: http://wise2.ipac.caltech.edu/docs/release/prelim/expsup/sec2_2a.html\n",
    "    print(\"Data has {} observations of {} unique asteroids.\".format(len(data), len(data[\"nameasstring\"].unique())))\n",
    "\n",
    "    # SNR cut: above 4 in all bands (similar to setting quality flag to B) (now set to above 4.0 in all bands)\n",
    "    snr = 4.0\n",
    "    snr_cuts = ((data[\"w1snr\"] >= snr) & (data[\"w2snr\"] >= snr) & (data[\"w3snr\"] >= snr) & (data[\"w4snr\"] >= snr)) \n",
    "\n",
    "    # Artifact flags: Should be 0 across all bands\n",
    "    artifact_cut = (data[\"cc_flags\"] == \"0000\")\n",
    "\n",
    "    # Quality flags: contains either A, B, C, does not contain U or X\n",
    "    quality_cut = ((data[\"ph_qual\"].str.contains(\"A\") |\n",
    "                    data[\"ph_qual\"].str.contains(\"B\") | \n",
    "                    data[\"ph_qual\"].str.contains(\"C\")) \n",
    "                   & (~data[\"ph_qual\"].str.contains(\"X\") \n",
    "                    & ~data[\"ph_qual\"].str.contains(\"U\")))\n",
    "    # Make initial cut\n",
    "    cut_data = data[snr_cuts & artifact_cut & quality_cut]\n",
    "\n",
    "    # Minimum observations in bands: (after all cuts have been made should be equivalent to just removing all asteroids that occur less than 3 times)\n",
    "    num_obs_per_asteroid = cut_data[\"nameasstring\"].value_counts()\n",
    "    keep = num_obs_per_asteroid[num_obs_per_asteroid >= 3]\n",
    "    cut_data = cut_data[cut_data[\"nameasstring\"].isin(keep.index)]\n",
    "    cut_data = cut_data.copy()\n",
    "    print(\"Cut data has {} observations of {} unique asteroids.\".format(len(cut_data), len(cut_data[\"nameasstring\"].unique())))\n",
    "\n",
    "\n",
    "    # We need fluxes and not magnitudes to do fitting\n",
    "    # Details on color correction and magnitudes: http://wise2.ipac.caltech.edu/docs/release/allsky/expsup/sec4_4h.html\n",
    "    # Details on values Nathan had are in section 2.7, https://arxiv.org/pdf/1605.06490.pdf, the same values are also available here:\n",
    "    mag_columns = [\"w1mpro\", \"w2mpro\", \"w3mpro\", \"w4mpro\"]\n",
    "    magErr_columns = [\"w1sigmpro\", \"w2sigmpro\", \"w3sigmpro\", \"w4sigmpro\"]\n",
    "    obs = WISE()\n",
    "    \n",
    "    flux_lambda = obs.convertMagToFluxLambda(cut_data[mag_columns].values)\n",
    "    fluxErr_lambda = obs.convertMagErrToFluxLambdaErr(cut_data[mag_columns].values, \n",
    "                                                      cut_data[magErr_columns].values)\n",
    "    cut_data[\"flux_W1_si\"] = flux_lambda[:, 0]\n",
    "    cut_data[\"flux_W2_si\"] = flux_lambda[:, 1]\n",
    "    cut_data[\"flux_W3_si\"] = flux_lambda[:, 2]\n",
    "    cut_data[\"flux_W4_si\"] = flux_lambda[:, 3]\n",
    "    cut_data[\"fluxErr_W1_si\"] = fluxErr_lambda[:, 0]\n",
    "    cut_data[\"fluxErr_W2_si\"] = fluxErr_lambda[:, 1]\n",
    "    cut_data[\"fluxErr_W3_si\"] = fluxErr_lambda[:, 2]\n",
    "    cut_data[\"fluxErr_W4_si\"] = fluxErr_lambda[:, 3]\n",
    "    cut_data[\"obs_id\"] = np.arange(1, len(cut_data) + 1) # Add obs_id column\n",
    "    \n",
    "    # Rename a few columns for user-friendliness\n",
    "    cut_data.rename(columns={\n",
    "        \"H from MPC\": \"H_mag\",\n",
    "        \"G from MPC\": \"G\",\n",
    "        \"ras - asteroid to sun (au)\" : \"r_au\",\n",
    "        \"rao - asteroid to WISE (au)\" : \"delta_au\", \n",
    "        \"alpha - phase angle (deg)\": \"alpha_deg\",\n",
    "        \"ra\":  \"ra_deg\",\n",
    "        \"dec\": \"dec_deg\",\n",
    "        \"sigra\" : \"ra_sigma_arcsec\",\n",
    "        \"sigdec\" : \"dec_sigma_arcsec\",\n",
    "        \"sigradec\" : \"radec_cosigma_arcsec\", \n",
    "        \"nameasstring\": \"designation\"},\n",
    "        inplace=True)\n",
    "\n",
    "    # Grab columns which will be convenient for modeling \n",
    "    need = ['obs_id', 'designation', 'r_au', 'delta_au', 'alpha_deg', 'H_mag', 'G', 'mjd', 'flux_W1_si',\n",
    "            'fluxErr_W1_si', 'flux_W2_si', 'fluxErr_W2_si', 'flux_W3_si',\n",
    "            'fluxErr_W3_si', 'flux_W4_si', 'fluxErr_W4_si']\n",
    "    # Grab remaining columns, add obs_id so a SQL join can be performed if desired\n",
    "    not_needed = set(cut_data.columns.values).difference(set(need))\n",
    "    not_needed.add(\"obs_id\")\n",
    "    not_needed = sorted(not_needed, key=list(not_needed).index)\n",
    "\n",
    "    # Split data into two DataFrames and arrange columns\n",
    "    observations = cut_data[need]\n",
    "    additional = cut_data[not_needed]\n",
    "    additional = additional[[\n",
    "        'obs_id', \n",
    "        'ra_deg', \n",
    "        'ra_sigma_arcsec', \n",
    "        'ra_u',\n",
    "        'dec_deg', \n",
    "        'dec_sigma_arcsec', \n",
    "        'dec_u', \n",
    "        'radec_cosigma_arcsec',\n",
    "        'w1mpro', \n",
    "        'w1rchi2', \n",
    "        'w1sat',\n",
    "        'w1sigmpro',\n",
    "        'w1snr',\n",
    "        'w2mpro',\n",
    "        'w2rchi2',\n",
    "        'w2sat',\n",
    "        'w2sigmpro',\n",
    "        'w2snr',\n",
    "        'w3mpro',\n",
    "        'w3rchi2',\n",
    "        'w3sat',\n",
    "        'w3sigmpro',\n",
    "        'w3snr',\n",
    "        'w4mpro',\n",
    "        'w4rchi2',\n",
    "        'w4sat',\n",
    "        'w4sigmpro',\n",
    "        'w4snr',\n",
    "        'cc_flags',\n",
    "        'cntr_u',\n",
    "        'dist_x',\n",
    "        'pang_x',\n",
    "        'ph_qual',\n",
    "        'na', \n",
    "        'nb',\n",
    "        'sso_flg']]\n",
    "    \n",
    "    # Calculate magnitudes and magnitude errors from flux lambda\n",
    "    mag = obs.convertFluxLambdaToMag(observations[[\"flux_W1_si\", \"flux_W2_si\", \"flux_W3_si\", \"flux_W4_si\"]].values)\n",
    "    magErr = obs.convertFluxLambdaErrToMagErr(observations[[\"flux_W1_si\", \"flux_W2_si\", \"flux_W3_si\", \"flux_W4_si\"]].values, \n",
    "                                              observations[[\"fluxErr_W1_si\", \"fluxErr_W2_si\", \"fluxErr_W3_si\", \"fluxErr_W4_si\"]].values)\n",
    "    mag_cols = []\n",
    "    magErr_cols = []\n",
    "\n",
    "    # Add magnitude and magnitude error columns to observations\n",
    "    for i, f in enumerate([\"W1\", \"W2\", \"W3\", \"W4\"]):\n",
    "        mag_col = \"mag_{}\".format(f)\n",
    "        magErr_col = \"magErr_{}\".format(f)\n",
    "        mag_cols.append(mag_col)\n",
    "        magErr_cols.append(magErr_col)\n",
    "        observations[mag_col] = mag[:, i]\n",
    "        observations[magErr_col] = magErr[:, i]\n",
    "    \n",
    "    # Notice that we calculated magnitudes from fluxes which were calculated from original magnitudes.. this is silly.\n",
    "    # Lets make sure the published magnitudes (in the additional DataFrame) are equivalent to the converted magnitudes\n",
    "    # in the observations DataFrame\n",
    "    pd.testing.assert_frame_equal(additional[mag_columns], observations[mag_cols].rename(columns={c1 : c2 for c1, c2 in zip(mag_cols, mag_columns)}))\n",
    "    \n",
    "    # Clip observations: add a \"keep\" column -- any observations that are over a magnitude\n",
    "    # away from a linear best fit model for each asteroid have keep set to 0. If any object\n",
    "    # has more than 42% of its observations that do not satisfy the cut criteria set keep to 0. \n",
    "    # If any object has less than three observations at the end of fitting the linear model set\n",
    "    # keep to 0 for all its observations.\n",
    "    # 42% was chosen to make sure that object 90367 was accepted. It fails at 40%.\n",
    "    # Note that if a single filters observation at an epoch is flagged, all other observations\n",
    "    # at the same epoch is also flagged, this may mean this clipping is more agressive than desired.\n",
    "    observations_flagged = clipObservations(observations, obs, magCut=1.0, minObs=3, maxObsCut=0.42)\n",
    "\n",
    "    # Add NEOWISE 2016 data to database\n",
    "    structure_lists = glob.glob(\"../data/neowise_diameters_albedos_V1_0/data/neowise_*.xml\")\n",
    "    neowisev1 = []\n",
    "\n",
    "    for sl in structure_lists:\n",
    "        neowise_data = pds4_tools.pds4_read(sl)\n",
    "        neowisev1.append(pd.DataFrame(neowise_data[\"TABLE\"].data))\n",
    "\n",
    "    neowisev1 = pd.concat(neowisev1, sort=False)\n",
    "    neowisev1.sort_values(by=\"ASTEROID_NUMBER\", inplace=True)\n",
    "    neowisev1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Attempts to crossmatch observations of minor planets with the NEOWISE results table. Adds a 'matched_designation' column to\n",
    "    # the NEOWISE results table with the matched designation from the observations table if found, if observations could not be matched\n",
    "    #to an asteroid in the NEOWISE table then 'matched_designation' will be set to NaN.\n",
    "    crossmatchNEOWISE(neowisev1, observations_flagged)\n",
    "    \n",
    "    # Save both DataFrames as tables in a sqlite database\n",
    "    con = sql.connect(DATABASE)\n",
    "    observations_flagged.to_sql(\"observations\", con, index=False)\n",
    "    additional.to_sql(\"additional\", con, index=False)\n",
    "    neowisev1.to_sql(\"neowise_v1\", con, index=False)\n",
    "    \n",
    "# Read data from database\n",
    "con = sql.connect(DATABASE)\n",
    "observations = pd.read_sql(\"\"\"SELECT * FROM observations\"\"\", con)\n",
    "additional = pd.read_sql(\"\"\"SELECT * FROM additional\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 2542956 observations of 150928 unique asteroids.\n",
      "Cut data has 2273455 observations of 149191 unique asteroids.\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_centaurs.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_irreg_sat.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_hildas.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_neos.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_mainbelt.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_ambos.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Processing label: ../data/neowise_diameters_albedos_V1_0/data/neowise_jupiter_trojans.xml\n",
      "Now processing a Table_Character structure: TABLE\n",
      "Crossmatched 128660 unique designations from observations with NEOWISE table.\n"
     ]
    }
   ],
   "source": [
    "DO_W3_PROCESSING = True\n",
    "DATABASE_W3= \"../data/sample_W3.db\"\n",
    "\n",
    "if DO_W3_PROCESSING is True:\n",
    "    ### Read in full data file\n",
    "    data = pd.read_csv(\"../data/fullcryoobservations.csv\", low_memory=False)\n",
    "\n",
    "    ### Sort values by name and mjd\n",
    "    data.sort_values(by=[\"nameasstring\", \"mjd\"], inplace=True)\n",
    "\n",
    "    ### Make same cuts as Nathan to produce a gold standard\n",
    "    #-          SNR >= 4.0\n",
    "    #-          Artifact flag = 0\n",
    "    #-          Quality flag = A, B, C\n",
    "    #-          Have at least 3 points in each of the four bands\n",
    "    # See: http://wise2.ipac.caltech.edu/docs/release/prelim/expsup/sec2_2a.html\n",
    "    print(\"Data has {} observations of {} unique asteroids.\".format(len(data), len(data[\"nameasstring\"].unique())))\n",
    "\n",
    "    # SNR cut: above 4 in all bands (similar to setting quality flag to B) (now set to above 4.0 in all bands)\n",
    "    snr_W3 = 4.0\n",
    "    snr_cuts_W3 = (data[\"w3snr\"] >= snr_W3)\n",
    "\n",
    "    # Artifact flags: Should be 0 across all bands\n",
    "    artifact_flags_W3 = data[\"cc_flags\"].str.slice(2, 3)\n",
    "    artifact_cut_W3 = (artifact_flags_W3  == \"0\")\n",
    "\n",
    "    # W3 only quality cut\n",
    "    quality_flag_W3 = data[\"ph_qual\"].str.slice(2, 3)\n",
    "    quality_cut_W3 = ((quality_flag_W3.str.contains(\"A\") |\n",
    "                    quality_flag_W3.str.contains(\"B\") | \n",
    "                    quality_flag_W3.str.contains(\"C\")) \n",
    "                   & (~quality_flag_W3.str.contains(\"X\") \n",
    "                    & ~quality_flag_W3.str.contains(\"U\")))\n",
    "\n",
    "    # Make initial cut\n",
    "    cut_data_W3 = data[snr_cuts_W3 & artifact_cut_W3 & quality_cut_W3]\n",
    "\n",
    "    # Minimum observations in bands: (after all cuts have been made should be equivalent to just removing all asteroids that occur less than 3 times)\n",
    "    num_obs_per_asteroid = cut_data_W3[\"nameasstring\"].value_counts()\n",
    "    keep = num_obs_per_asteroid[num_obs_per_asteroid >= 3]\n",
    "    cut_data_W3 = cut_data_W3[cut_data_W3[\"nameasstring\"].isin(keep.index)]\n",
    "    cut_data_W3 = cut_data_W3.copy()\n",
    "    print(\"Cut data has {} observations of {} unique asteroids.\".format(len(cut_data_W3), len(cut_data_W3[\"nameasstring\"].unique())))\n",
    "\n",
    "    # We need fluxes and not magnitudes to do fitting\n",
    "    # Details on color correction and magnitudes: http://wise2.ipac.caltech.edu/docs/release/allsky/expsup/sec4_4h.html\n",
    "    # Details on values Nathan had are in section 2.7, https://arxiv.org/pdf/1605.06490.pdf, the same values are also available here:\n",
    "    mag_columns = [\"w1mpro\", \"w2mpro\", \"w3mpro\", \"w4mpro\"]\n",
    "    magErr_columns = [\"w1sigmpro\", \"w2sigmpro\", \"w3sigmpro\", \"w4sigmpro\"]\n",
    "    obs = WISE()\n",
    "    \n",
    "    flux_lambda = obs.convertMagToFluxLambda(cut_data_W3[mag_columns].values)\n",
    "    fluxErr_lambda = obs.convertMagErrToFluxLambdaErr(cut_data_W3[mag_columns].values, cut_data_W3[magErr_columns].values)\n",
    "    cut_data_W3[\"flux_W3_si\"] = flux_lambda[:, 2]\n",
    "    cut_data_W3[\"fluxErr_W3_si\"] = fluxErr_lambda[:, 2]\n",
    "    cut_data_W3[\"mag_W3\"] = cut_data_W3[\"w3mpro\"]\n",
    "    cut_data_W3[\"magErr_W3\"] = cut_data_W3[\"w3sigmpro\"]\n",
    "    cut_data_W3[\"obs_id\"] = np.arange(1, len(cut_data_W3) + 1) # Add obs_id column\n",
    "    \n",
    "    # Rename a few columns for user-friendliness\n",
    "    cut_data_W3.rename(columns={\n",
    "        \"H from MPC\": \"H_mag\",\n",
    "        \"G from MPC\": \"G\",\n",
    "        \"ras - asteroid to sun (au)\" : \"r_au\",\n",
    "        \"rao - asteroid to WISE (au)\" : \"delta_au\", \n",
    "        \"alpha - phase angle (deg)\": \"alpha_deg\",\n",
    "        \"ra\":  \"ra_deg\",\n",
    "        \"dec\": \"dec_deg\",\n",
    "        \"sigra\" : \"ra_sigma_arcsec\",\n",
    "        \"sigdec\" : \"dec_sigma_arcsec\",\n",
    "        \"sigradec\" : \"radec_cosigma_arcsec\", \n",
    "        \"nameasstring\": \"designation\"},\n",
    "        inplace=True)\n",
    "\n",
    "    # Grab columns which will be convenient for modeling \n",
    "    need = ['obs_id', 'designation', 'r_au', 'delta_au', 'alpha_deg', 'H_mag', 'G', 'mjd', 'flux_W3_si',\n",
    "            'fluxErr_W3_si', \"mag_W3\", \"magErr_W3\"]\n",
    "    # Grab remaining columns, add obs_id so a SQL join can be performed if desired\n",
    "    not_needed = set(cut_data_W3.columns.values).difference(set(need))\n",
    "    not_needed.add(\"obs_id\")\n",
    "    not_needed = sorted(not_needed, key=list(not_needed).index)\n",
    "\n",
    "    # Split data into two DataFrames and arrange columns\n",
    "    observations = cut_data_W3[need]\n",
    "    additional = cut_data_W3[not_needed]\n",
    "    additional = additional[[\n",
    "        'obs_id', \n",
    "        'ra_deg', \n",
    "        'ra_sigma_arcsec', \n",
    "        'ra_u',\n",
    "        'dec_deg', \n",
    "        'dec_sigma_arcsec', \n",
    "        'dec_u', \n",
    "        'radec_cosigma_arcsec', \n",
    "        'w1mpro', \n",
    "        'w1rchi2', \n",
    "        'w1sat',\n",
    "        'w1sigmpro',\n",
    "        'w1snr',\n",
    "        'w2mpro',\n",
    "        'w2rchi2',\n",
    "        'w2sat',\n",
    "        'w2sigmpro',\n",
    "        'w2snr',\n",
    "        'w3mpro',\n",
    "        'w3rchi2',\n",
    "        'w3sat',\n",
    "        'w3sigmpro',\n",
    "        'w3snr',\n",
    "        'w4mpro',\n",
    "        'w4rchi2',\n",
    "        'w4sat',\n",
    "        'w4sigmpro',\n",
    "        'w4snr',\n",
    "        'cc_flags',\n",
    "        'cntr_u',\n",
    "        'dist_x',\n",
    "        'pang_x',\n",
    "        'ph_qual',\n",
    "        'na', \n",
    "        'nb',\n",
    "        'sso_flg']]\n",
    "    \n",
    "    # Add NEOWISE 2016 data to database\n",
    "    structure_lists = glob.glob(\"../data/neowise_diameters_albedos_V1_0/data/neowise_*.xml\")\n",
    "    neowisev1 = []\n",
    "\n",
    "    for sl in structure_lists:\n",
    "        neowise_data = pds4_tools.pds4_read(sl)\n",
    "        neowisev1.append(pd.DataFrame(neowise_data[\"TABLE\"].data))\n",
    "\n",
    "    neowisev1 = pd.concat(neowisev1, sort=False)\n",
    "    neowisev1.sort_values(by=\"ASTEROID_NUMBER\", inplace=True)\n",
    "    neowisev1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Attempts to crossmatch observations of minor planets with the NEOWISE results table. Adds a 'matched_designation' column to\n",
    "    # the NEOWISE results table with the matched designation from the observations table if found, if observations could not be matched\n",
    "    #to an asteroid in the NEOWISE table then 'matched_designation' will be set to NaN.\n",
    "    crossmatchNEOWISE(neowisev1, observations)\n",
    "    \n",
    "    # Save both DataFrames as tables in a sqlite database\n",
    "    con = sql.connect(DATABASE_W3)\n",
    "    observations.to_sql(\"observations\", con, index=False)\n",
    "    additional.to_sql(\"additional\", con, index=False)\n",
    "    neowisev1.to_sql(\"neowise_v1\", con, index=False)\n",
    "    \n",
    "# Read data from database\n",
    "con = sql.connect(DATABASE_W3)\n",
    "observations = pd.read_sql(\"\"\"SELECT * FROM observations\"\"\", con)\n",
    "additional = pd.read_sql(\"\"\"SELECT * FROM additional\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATM (Python 3.6)",
   "language": "python",
   "name": "atm_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
